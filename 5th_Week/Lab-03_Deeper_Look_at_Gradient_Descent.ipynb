{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deeper_Look_at_Gradient_Descent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "U-Xkp6JtECso"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Hypothesis (Linear Regression)"
      ],
      "metadata": {
        "id": "xGj1J0ZMDu7t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "168vITdS9mr0",
        "outputId": "802be0f9-bd64-4572-c72b-01340f0820c2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b4a243e862b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ],
      "source": [
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "hypothesis = x_train * W + b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Simpler Hypothesis Function"
      ],
      "metadata": {
        "id": "sia-k_FTEWQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros(1, requires_grad=True)\n",
        "# b = torch.zeros(1, requires_grad=True)\n",
        "hypothesis = x_train * W"
      ],
      "metadata": {
        "id": "gy-7_IviEZ64"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])"
      ],
      "metadata": {
        "id": "7DIw6_NPGJJR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Cost function : MSE"
      ],
      "metadata": {
        "id": "PUpZaQ9oGXWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost = torch.mean((hypothesis - y_train) ** 2)"
      ],
      "metadata": {
        "id": "OTB8cynNGZlR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient = 2 * torch.mean((W * x_train - y_train) * x_train)\n",
        "lr = 0.1\n",
        "W = W - lr * gradient"
      ],
      "metadata": {
        "id": "qHEWRqRtHZST"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Full Code"
      ],
      "metadata": {
        "id": "x9FPRafHH0Mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1)\n",
        "\n",
        "# Learning rate 설정\n",
        "lr = 0.1\n",
        "\n",
        "nb_epochs = 10\n",
        "\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W\n",
        "\n",
        "    # cost gradient 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "    gradient = torch.sum((W * x_train - y_train) * x_train)\n",
        "\n",
        "    print('Epoch {:4d}/{} W: {:.3f}, Cost: {:.6f}'.format(epoch, nb_epochs, W.item(), cost.item()))\n",
        "\n",
        "    # cost gradient로 H(x)개선\n",
        "    W -= lr * gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isFfGJTSH1_3",
        "outputId": "743b085c-d666-4fcb-9083-874e1dc1a158"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/10 W: 0.000, Cost: 4.666667\n",
            "Epoch    1/10 W: 1.400, Cost: 0.746666\n",
            "Epoch    2/10 W: 0.840, Cost: 0.119467\n",
            "Epoch    3/10 W: 1.064, Cost: 0.019115\n",
            "Epoch    4/10 W: 0.974, Cost: 0.003058\n",
            "Epoch    5/10 W: 1.010, Cost: 0.000489\n",
            "Epoch    6/10 W: 0.996, Cost: 0.000078\n",
            "Epoch    7/10 W: 1.002, Cost: 0.000013\n",
            "Epoch    8/10 W: 0.999, Cost: 0.000002\n",
            "Epoch    9/10 W: 1.000, Cost: 0.000000\n",
            "Epoch   10/10 W: 1.000, Cost: 0.000000\n"
          ]
        }
      ]
    }
  ]
}